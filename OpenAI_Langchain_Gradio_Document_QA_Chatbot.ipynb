{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcM9p/bOdtRd7nDz0wNseo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikeyanrathinam/Large-Language-Models-LLM/blob/main/OpenAI_Langchain_Gradio_Document_QA_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The OpenAI Langchain Document QA:\n",
        "\n",
        "![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)![OpenAI](https://img.shields.io/badge/OpenAI-412991.svg?style=for-the-badge&logo=OpenAI&logoColor=white)![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)![Visual Studio Code](https://img.shields.io/badge/Visual%20Studio%20Code-0078d7.svg?style=for-the-badge&logo=visual-studio-code&logoColor=white)![Kaggle](https://img.shields.io/badge/Kaggle-035a7d?style=for-the-badge&logo=kaggle&logoColor=white)![Google Drive](https://img.shields.io/badge/Google%20Drive-4285F4?style=for-the-badge&logo=googledrive&logoColor=white)![Linux](https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&logo=linux&logoColor=black)![Kali](https://img.shields.io/badge/Kali-268BEE?style=for-the-badge&logo=kalilinux&logoColor=white)![Postman](https://img.shields.io/badge/Postman-FF6C37?style=for-the-badge&logo=postman&logoColor=white)![Git](https://img.shields.io/badge/git-%23F05033.svg?style=for-the-badge&logo=git&logoColor=white)![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)![Google](https://img.shields.io/badge/google-4285F4?style=for-the-badge&logo=google&logoColor=white)![DuckDuckGo](https://img.shields.io/badge/DuckDuckGo-DE5833?style=for-the-badge&logo=DuckDuckGo&logoColor=white)![Edge](https://img.shields.io/badge/Microsoft%20Edge-0078D7.svg?style=for-the-badge&logo=Microsoft-Edge&logoColor=white)![Windows](https://img.shields.io/badge/Windows-0078D6?style=for-the-badge&logo=windows&logoColor=white)![Windows 11](https://img.shields.io/badge/Windows%2011-%230079d5.svg?style=for-the-badge&logo=Windows%2011&logoColor=white)![Open Project](https://img.shields.io/badge/OpenProject-0770B8.svg?style=for-the-badge&logo=OpenProject&logoColor=white)![Open Access](https://img.shields.io/badge/Open%20Access-F68212.svg?style=for-the-badge&logo=Open-Access&logoColor=white)\n",
        "\n",
        "# **Let's connect :**\n",
        "\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-181717.svg?style=for-the-badge&logo=GitHub&logoColor=white)](https://github.com/karthikeyanrathinam/)\n",
        "[![Linkedin](https://img.shields.io/badge/LinkedIn-0A66C2.svg?style=for-the-badge&logo=LinkedIn&logoColor=white)](https://www.linkedin.com/in/karthikeyanrathinam/)\n",
        "[![YouTube](https://img.shields.io/badge/YouTube-FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/@linkagethink)\n",
        "[![Gmail](https://img.shields.io/badge/Gmail-EA4335.svg?style=for-the-badge&logo=Gmail&logoColor=white)](mailto:karthikeyanr1801@gmail.com)\n",
        "\n",
        "Here is an explanation of the OpenAI Langchain Document QA code:\n",
        "\n",
        "## The main components:\n",
        "\n",
        "- `UnstructuredFileLoader` - Loads documents from various file types (txt, pdf, docx, etc) into a list of text documents that Langchain can process.\n",
        "\n",
        "- `OpenAIEmbeddings` - Creates vector embeddings for each chunk of text using OpenAI's embedding model. This encodes the semantic meaning of each chunk.\n",
        "\n",
        "- `FAISS` - Indexes the vector embeddings to create the actual searchable knowledge base. This allows fast similarity search over the embeddings/documents.\n",
        "\n",
        "- `CharacterTextSplitter` - Splits the documents into smaller chunks before embedding. This allows embedding documents of arbitrary size.\n",
        "\n",
        "- `load_qa_chain` - Loads a pretrained QA model from Langchain using the OpenAI LLM. This is a T5 model fine-tuned for question answering.\n",
        "\n",
        "## The main functions:\n",
        "\n",
        "- `create_knowledge_base` - Takes documents, splits them, embeds them and indexes into a knowledge base.\n",
        "\n",
        "- `upload_file` - Handler for uploading a local file. Loads it and creates the knowledge base.\n",
        "\n",
        "- `upload_via_url` - Handles a URL, downloads the content, and loads it.\n",
        "\n",
        "- `answer_question` - Takes a question and searches the knowledge base embeddings to find the most relevant passage. Passes this to the QA model to generate an answer.\n",
        "\n",
        "## The Gradio app:\n",
        "\n",
        "- Allows uploading local files or entering URLs to populate the knowledge base.\n",
        "\n",
        "- Provides a textbox to enter a question.\n",
        "\n",
        "- Displays the generated answer returned by the QA model.\n",
        "\n",
        "# Loading documents\n",
        "\n",
        "The `UnstructuredFileLoader` handles ingesting files of different formats like PDF, DOC, TXT etc.\n",
        "\n",
        "```python\n",
        "loader = UnstructuredFileLoader(file_path, strategy=\"fast\")\n",
        "docs = loader.load()\n",
        "```\n",
        "\n",
        "It uses heuristic strategies to extract text content from these file types.\n",
        "\n",
        "The resulting `docs` is a list of text snippets representing the contents of the uploaded file.\n",
        "\n",
        "# Text Splitting\n",
        "\n",
        "The `CharacterTextSplitter` splits the loaded documents into smaller chunks:\n",
        "\n",
        "```python\n",
        "text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=500, chunk_overlap=0)\n",
        "chunks = text_splitter.split_documents(docs)\n",
        "```\n",
        "\n",
        "This is done because large documents can't be embedded efficiently in one go. The chunks will be embedded separately.\n",
        "\n",
        "# Embedding\n",
        "\n",
        "The `OpenAIEmbeddings` module is used to generate vector embeddings for each chunk:\n",
        "\n",
        "```python\n",
        "embeddings = OpenAIEmbeddings()\n",
        "```\n",
        "\n",
        "This uses OpenAI's text-embedding-ada-002 model under the hood.\n",
        "\n",
        "# Indexing\n",
        "\n",
        "The vector embeddings for each chunk are indexed using FAISS for fast similarity search:\n",
        "\n",
        "```python\n",
        "knowledge_base = FAISS.from_documents(chunks, embeddings)\n",
        "```\n",
        "\n",
        "This indexing allows finding the most relevant chunks for a query.\n",
        "\n",
        "# Question Answering\n",
        "\n",
        "Given a user question, relevant chunks are retrieved by searching the knowledge base index:\n",
        "\n",
        "```python\n",
        "docs = knowledge_base.similarity_search(question)\n",
        "```\n",
        "\n",
        "These chunks are passed to a QA model to generate the answer:\n",
        "\n",
        "```python\n",
        "llm = OpenAI()\n",
        "chain = load_qa_chain(llm)\n",
        "response = chain.run(docs, question)\n",
        "```\n",
        "\n",
        "The `load_qa_chain` helper sets up the QA model using the OpenAI API.\n",
        "\n",
        "So in summary, it provides an end-to-end pipeline for uploading documents, indexing them for search, and leveraging a QA model to answer questions based on the uploaded doc contents.\n",
        "\n",
        "# **Follow**\n",
        "Feel free to reach out if you have any questions or need further assistance.\n",
        "\n",
        "\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-181717.svg?style=for-the-badge&logo=GitHub&logoColor=white)](https://github.com/karthikeyanrathinam/)\n",
        "[![Linkedin](https://img.shields.io/badge/LinkedIn-0A66C2.svg?style=for-the-badge&logo=LinkedIn&logoColor=white)](https://www.linkedin.com/in/karthikeyanrathinam/)\n",
        "[![YouTube](https://img.shields.io/badge/YouTube-FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/@linkagethink)\n",
        "[![Gmail](https://img.shields.io/badge/Gmail-EA4335.svg?style=for-the-badge&logo=Gmail&logoColor=white)](mailto:karthikeyanr1801@gmail.com)\n"
      ],
      "metadata": {
        "id": "AW-jAAICeEWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "openai\n",
        "tiktoken\n",
        "langchain\n",
        "gradio\n",
        "pypdf\n",
        "requests\n",
        "validators\n",
        "pytesseract\n",
        "pdf2image\n",
        "tabulate\n",
        "nltk\n",
        "python-dotenv\n",
        "faiss-cpu\n",
        "unstructured[all-docs]\n",
        "pydantic-settings"
      ],
      "metadata": {
        "id": "AMO1ItaeeDyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile style.css\n",
        "#col-container {\n",
        "  max-width: 700px;\n",
        "  margin-left: auto;\n",
        "  margin-right: auto;\n",
        "}\n",
        "#row-flex {\n",
        "  display: flex;\n",
        "  align-items: center;\n",
        "  justify-content: center;\n",
        "}\n",
        ".filenameshow{\n",
        "  height:85px;\n",
        "}\n",
        ".spaceH{\n",
        "  padding-top:45px;\n",
        "}\n",
        ".leftimage .rightimage{\n",
        "  float:left;\n",
        "}\n",
        ".leftimage{\n",
        "  display: inline-block;\n",
        "  padding-top:26px;\n",
        "  padding-left:170px;\n",
        "}\n",
        ".rightimage{\n",
        "  display: inline-block;\n",
        "  padding-top:15px;\n",
        "  margin-right:190px;\n",
        "}"
      ],
      "metadata": {
        "id": "-p0JNR6yfF09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "OPENAI_API_KEY = sk-....................."
      ],
      "metadata": {
        "id": "OAH9KDUWfPjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV7Oo8Fmb70a"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from pypdf import PdfReader\n",
        "import mimetypes\n",
        "import validators\n",
        "import requests\n",
        "import tempfile\n",
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "\n",
        "def get_empty_state():\n",
        "    return {\"knowledge_base\": None}\n",
        "\n",
        "\n",
        "def create_knowledge_base(docs):\n",
        "    # split into chunks\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\", chunk_size=500, chunk_overlap=0, length_function=len\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(docs)\n",
        "\n",
        "    # Create embeddings\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    knowledge_base = FAISS.from_documents(chunks, embeddings)\n",
        "    return knowledge_base\n",
        "\n",
        "\n",
        "def upload_file(file_obj):\n",
        "    try:\n",
        "      loader = UnstructuredFileLoader(file_obj.name, strategy=\"fast\")\n",
        "      docs = loader.load()\n",
        "\n",
        "      knowledge_base = create_knowledge_base(docs)\n",
        "    except:\n",
        "      text=\"Try Another file\"\n",
        "      return  file_obj.name, text\n",
        "\n",
        "    return file_obj.name, {\"knowledge_base\": knowledge_base}\n",
        "\n",
        "\n",
        "def upload_via_url(url):\n",
        "    if validators.url(url):\n",
        "        r = requests.get(url)\n",
        "\n",
        "        if r.status_code != 200:\n",
        "            raise ValueError(\n",
        "                \"Check the url of your file; returned status code %s\" % r.status_code\n",
        "            )\n",
        "\n",
        "        content_type = r.headers.get(\"content-type\")\n",
        "        file_extension = mimetypes.guess_extension(content_type)\n",
        "        temp_file = tempfile.NamedTemporaryFile(suffix=file_extension, delete=False)\n",
        "        temp_file.write(r.content)\n",
        "        file_path = temp_file.name\n",
        "        loader = UnstructuredFileLoader(file_path, strategy=\"fast\",post_processors=[clean_extra_whitespace])\n",
        "        docs = loader.load()\n",
        "        knowledge_base = create_knowledge_base(docs)\n",
        "        return file_path, {\"knowledge_base\": knowledge_base}\n",
        "    else:\n",
        "        raise ValueError(\"Please enter a valid URL\")\n",
        "\n",
        "\n",
        "def answer_question(question, state):\n",
        "\n",
        "    try:\n",
        "        knowledge_base = state[\"knowledge_base\"]\n",
        "        docs = knowledge_base.similarity_search(question)\n",
        "\n",
        "        llm = OpenAI(temperature=0.4)\n",
        "        chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "        response = chain.run(input_documents=docs, question=question)\n",
        "        return response\n",
        "    except:\n",
        "        return \"Please upload Proper Document\"\n",
        "\n",
        "\n",
        "with gr.Blocks(css=\"style.css\",theme=gr.themes.Soft()) as demo:\n",
        "    state = gr.State(get_empty_state())\n",
        "    gr.HTML(\"\"\"LINKAGETHINK\"\"\")\n",
        "    with gr.Column(elem_id=\"col-container\"):\n",
        "        gr.HTML(\n",
        "            \"\"\"<hr style=\"border-top: 5px solid white;\">\"\"\"\n",
        "            )\n",
        "        gr.HTML(\n",
        "            \"\"\"<br>\n",
        "            <h1 style=\"text-align:center;\">\n",
        "               OPENAI Document QA\n",
        "              </h1> \"\"\"\n",
        "        )\n",
        "        gr.HTML(\n",
        "            \"\"\"<hr style=\"border-top: 5px solid white;\">\"\"\"\n",
        "            )\n",
        "\n",
        "        gr.Markdown(\"**Upload your file**\")\n",
        "        with gr.Row(elem_id=\"row-flex\"):\n",
        "            with gr.Column(scale=0.85):\n",
        "                file_url = gr.Textbox(\n",
        "                    value=\"\",\n",
        "                    label=\"Upload your file\",\n",
        "                    placeholder=\"Enter a url\",\n",
        "                    show_label=False,\n",
        "                    visible=False\n",
        "                )\n",
        "            with gr.Column(scale=0.90, min_width=160):\n",
        "                file_output = gr.File(elem_classes=\"filenameshow\")\n",
        "            with gr.Column(scale=0.10, min_width=160):\n",
        "                upload_button = gr.UploadButton(\n",
        "                    \"Browse File\",file_types=[\".txt\", \".pdf\", \".doc\", \".docx\",\".json\",\".csv\"],\n",
        "                    elem_classes=\"filenameshow\")\n",
        "        with gr.Row():\n",
        "          with gr.Column(scale=1, min_width=0):\n",
        "            user_question = gr.Textbox(value=\"\",label='Question Box :',show_label=True, placeholder=\"Ask a question about your file:\",elem_classes=\"spaceH\")\n",
        "        with gr.Row():\n",
        "          with gr.Column(scale=1, min_width=0):\n",
        "            answer = gr.Textbox(value=\"\",label='Answer Box :',show_label=True, placeholder=\"\",lines=5)\n",
        "\n",
        "    file_url.submit(upload_via_url, file_url, [file_output, state])\n",
        "    upload_button.upload(upload_file, upload_button, [file_output,state])\n",
        "    user_question.submit(answer_question, [user_question, state], [answer])\n",
        "\n",
        "demo.queue().launch()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "apDJ70RKe4or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py"
      ],
      "metadata": {
        "id": "-_o4d8-Wfd2j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
