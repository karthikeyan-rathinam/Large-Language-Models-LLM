{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikeyanrathinam/Large-Language-Models-LLM/blob/main/LangChain%2COpenAI%2C_Pinecone_with_Custom_Document_Gradio_ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)![Visual Studio Code](https://img.shields.io/badge/Visual%20Studio%20Code-0078d7.svg?style=for-the-badge&logo=visual-studio-code&logoColor=white)![Kaggle](https://img.shields.io/badge/Kaggle-035a7d?style=for-the-badge&logo=kaggle&logoColor=white)![Google Drive](https://img.shields.io/badge/Google%20Drive-4285F4?style=for-the-badge&logo=googledrive&logoColor=white)![Linux](https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&logo=linux&logoColor=black)![Kali](https://img.shields.io/badge/Kali-268BEE?style=for-the-badge&logo=kalilinux&logoColor=white)![Git](https://img.shields.io/badge/git-%23F05033.svg?style=for-the-badge&logo=git&logoColor=white)![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)![Google](https://img.shields.io/badge/google-4285F4?style=for-the-badge&logo=google&logoColor=white)![DuckDuckGo](https://img.shields.io/badge/DuckDuckGo-DE5833?style=for-the-badge&logo=DuckDuckGo&logoColor=white)![Windows](https://img.shields.io/badge/Windows-0078D6?style=for-the-badge&logo=windows&logoColor=white)\n",
        "\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-181717.svg?style=for-the-badge&logo=GitHub&logoColor=white)](https://github.com/karthikeyanrathinam/)\n",
        "[![Linkedin](https://img.shields.io/badge/LinkedIn-0A66C2.svg?style=for-the-badge&logo=LinkedIn&logoColor=white)](https://www.linkedin.com/in/karthikeyanrathinam/)\n",
        "[![YouTube](https://img.shields.io/badge/YouTube-FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/@linkagethink)\n",
        "[![Gmail](https://img.shields.io/badge/Gmail-EA4335.svg?style=for-the-badge&logo=Gmail&logoColor=white)](mailto:karthikeyanr1801@gmail.com)\n",
        "\n",
        "## **LangChain, OpenAI, Pinecone with Custom Document Gradio ChatBot**\n",
        "\n",
        "This Python script is designed to extract data from a PDF file value from that data. It utilizes various libraries, including `langchain`, `unstructured`, `pandas`, `numpy`, `chromadb`, `openai` and `tiktoken`. Additionally, it includes a Gradio interface for user interaction.\n",
        "*\tImport necessary libraries.\n",
        "  ```python\n",
        "  import gradio as gr\n",
        "  from langchain.document_loaders import UnstructuredPDFLoader\n",
        "  from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "  from langchain.vectorstores import Pinecone\n",
        "  from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "  from langchain.llms import OpenAI\n",
        "  from langchain.chains.question_answering import load_qa_chain\n",
        "  import pinecone\n",
        "  ```\n",
        "## **Pre-Requests**\n",
        "```python\n",
        "> OPENAI_API_KEY = '---'\n",
        "> PINECONE_API_KEY = '---'\n",
        "> PINECONE_API_ENV = '---'\n",
        "> index_name = \"---\"\n",
        "```\n",
        "\n",
        "## **Usage**\n",
        "To use this script, follow these steps:\n",
        "1. Clone this repository to your local machine.\n",
        "â€‹\n",
        "  ```shell\n",
        "    git clone https://github.com/karthikeyanrathinam/Langchain-chatbot-with-openai.git\n",
        "  ```\n",
        "2. Install the required Python libraries mentioned in the script.\n",
        "  ```shell\n",
        "  cd Langchain-chatbot-with-openai\n",
        "  pip install -r requirements.txt\n",
        " ```\n",
        "4. Run the script, and the Gradio interface will open in your browser.\n",
        "  ```shell\n",
        "    iface.launch()\n",
        "  ```\n",
        "5. Upload a PDF file, Make a query.\n",
        "\n",
        "## **Contributing**\n",
        "Contributions to this project are welcome! If you'd like to contribute, please open an issue or submit a pull request.\n",
        "\n",
        "## **License**\n",
        "This project is licensed under the MIT License.\n",
        "\n",
        "## **Follow**\n",
        "\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-181717.svg?style=for-the-badge&logo=GitHub&logoColor=white)](https://github.com/karthikeyanrathinam/)\n",
        "[![Linkedin](https://img.shields.io/badge/LinkedIn-0A66C2.svg?style=for-the-badge&logo=LinkedIn&logoColor=white)](https://www.linkedin.com/in/karthikeyanrathinam/)\n",
        "[![YouTube](https://img.shields.io/badge/YouTube-FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/@linkagethink)\n",
        "[![Gmail](https://img.shields.io/badge/Gmail-EA4335.svg?style=for-the-badge&logo=Gmail&logoColor=white)](mailto:karthikeyanr1801@gmail.com)\n",
        "\n"
      ],
      "metadata": {
        "id": "iID28zthfhdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "langchain\n",
        "unstructured\n",
        "pandas\n",
        "chromadb\n",
        "tiktoken\n",
        "openai"
      ],
      "metadata": {
        "id": "zoGEbkU_8Gkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "oDJsZDEIfUVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxtegzm_7-M0"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt -q\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!sudo apt-get install poppler-utils\n",
        "!pip install pdf2image pytesseract\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html\n",
        "!pip install -qU pinecone-client\n",
        "!pip install adaptive\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import gradio as gr\n",
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "import pinecone\n",
        "\n",
        "OPENAI_API_KEY = '---'\n",
        "PINECONE_API_KEY = '---'\n",
        "PINECONE_API_ENV = '---'\n",
        "index_name = \"---\"\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,\n",
        "    environment=PINECONE_API_ENV\n",
        ")\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "def load_pdf_document(file_path):\n",
        "    loader = UnstructuredPDFLoader(file_path)\n",
        "    return loader.load()\n",
        "\n",
        "def split_document_to_chunks(documents):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    return text_splitter.split_documents(documents)\n",
        "\n",
        "def documentsearch(texts, embeddings, index_name):\n",
        "    return Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)\n",
        "\n",
        "def responces(query, docsearch):\n",
        "    docs = docsearch.similarity_search(query, include_metadata=True)\n",
        "    return chain.run(input_documents=docs, question=query)\n",
        "\n",
        "docsearch = None\n",
        "history = []\n",
        "\n",
        "def chatbot(file, question):\n",
        "    global history\n",
        "    global docsearch\n",
        "    if file is not None:\n",
        "        data = load_pdf_document(file.name)\n",
        "        texts = split_document_to_chunks(data)\n",
        "        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "        docsearch = documentsearch(texts, embeddings, index_name)\n",
        "    if docsearch is not None and question is not None:\n",
        "        history.append((\"User\", question))\n",
        "        response = responces(question, docsearch)\n",
        "        history.append((\"Bot\", response))\n",
        "    return history\n",
        "\n",
        "iface = gr.Interface(fn=chatbot, inputs=[\"file\", \"text\"], outputs=\"list\")\n",
        "\n",
        "def clear_chat():\n",
        "    global history\n",
        "    history = []\n",
        "    iface.update_chat([])\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "_c-nx8Lo7_Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python app.py"
      ],
      "metadata": {
        "id": "hGX4VUQUgE6A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
